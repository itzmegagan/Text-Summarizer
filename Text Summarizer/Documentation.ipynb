{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZOys8MXXUrl",
    "colab_type": "text"
   },
   "source": [
    "## Text Summarization: Taking a paragraph as the input and getting a one-line summary for that paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVVCgKn8XqN6",
    "colab_type": "text"
   },
   "source": [
    "The main objetive of a text summarizer is to give an output which states the important points or the summary of the given paragraph.\n",
    "\n",
    "Steps involved:\n",
    "\n",
    "1. Take a formatted input paragraph ie a paragraph without special characters or brackets.\n",
    "\n",
    "2. Remove the stopwords from the paragraph to get a clear  data.\n",
    "\n",
    "2. Break the paragraph into sentences and words using tokenization.\n",
    "\n",
    "3. Calculate the frequency of each word which is not a stopword with the help of a frequency table.\n",
    "\n",
    "4. Calculate the value of a sentence based on the frequency of the words. Value gives the weightage to the     sentence.\n",
    "\n",
    "5. Find the average value of the sentences and compare every sentence to this average and thereby form a summary by adding the sentences. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8P_k-LWg6Zh",
    "colab_type": "text"
   },
   "source": [
    "### **Procedure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkPt8-3ChtM7",
    "colab_type": "text"
   },
   "source": [
    "Import NLP libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JmtdV2-ghyDf",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('treebank')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rfTRxiPh-ZK",
    "colab_type": "text"
   },
   "source": [
    "Take a user input paragraph. Make sure to avoid special characters and brackets in your input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "oXGPCmo_iJnC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "para = input(\"Please enter a paragraph:\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0T_5LPWiRVd",
    "colab_type": "text"
   },
   "source": [
    "Tokenize the words and remove the stopwords. Also make a frequency table. For this we have to make two arrays , one for stopwords and the other for every word in the paragraph. Then create a dictionary for frequency table for words. For this use the words which are not in stopwords array.  Calculate maxium frequency and divide every word with the maximum frequency to get the proper weightage of the word \n",
    "Now freqtable dictionary can be used over every sentence to know which sentences have more importance to the overall context of the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "YnOnbptqjc2-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "words = word_tokenize(para)\n",
    "\n",
    "freqtable = {}\n",
    "for word in words:\n",
    "  word = word.lower()\n",
    "  if word in stopWords:\n",
    "    continue\n",
    "  if word in freqtable.keys():\n",
    "      freqtable[word] += 1\n",
    "  else:\n",
    "      freqtable[word] = 1\n",
    "    \n",
    "max_freq = max(freqtable.values())\n",
    "\n",
    "for word in freqtable.keys():\n",
    "  freqtable[word] = (freqtable[word]/max_freq)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymTr_T81kupb",
    "colab_type": "text"
   },
   "source": [
    "Tokenize the sentences by running the method to create an array of sentences. Create a dictionary to store the values of each sentence. Go through every sentence and give it a value depending on the words it has. This is done by adding the frequency of every nonstop word in a sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4u-AXChtlH1Z",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(para)\n",
    "\n",
    "sentvalue = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "  for word in word_tokenize(sentence.lower()):\n",
    "    if word in freqtable.keys():\n",
    "      if len(sentence.split(' '))<30:\n",
    "        if sentence in sentvalue.keys():\n",
    "          sentvalue[sentence] += freqtable[word]\n",
    "        else:\n",
    "          sentvalue[sentence] = freqtable[word]\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgN_A-YDmMCa",
    "colab_type": "text"
   },
   "source": [
    "Calculate the average value by adding all the values and then dividing this sum by the length of the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XTCaeOBCmO_P",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "sumvalue = 0\n",
    "for sentence in sentvalue:\n",
    "  sumvalue += sentvalue[sentence]\n",
    "  \n",
    "average = int(sumvalue/len(sentvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uz-6zjvwm6mi",
    "colab_type": "text"
   },
   "source": [
    "Run a loop to compare the value to a threshold. In this case we take one-fifth of the average value as the threshold. Go on adding the sentences to form a meaningful summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "A_96RYVum7O-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "summary = ' '\n",
    "for sentence in sentences:\n",
    "  if (sentence in sentvalue) and (sentvalue[sentence]) > (1.5*average):\n",
    "    summary += \" \" + sentence\n",
    "print(\"The summary of the given paragraph is:\\n\",summary)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Documentation.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
